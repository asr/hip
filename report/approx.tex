\section{Approximation Lemma}
\label{sec:approx}

The approximation lemma is another standard technique for proving
properties about corecursive programs. It has similar properties as
fixed point induction: it is applicable on functions that produce
infinite values and with no argument viable for structural induction.
However, it is simpler to apply. \citep{corecursive}. The key idea for
equality over lists is to show that all prefixes of the sides
coincide; i.e their approximations are equal.

The approximation lemma supersedes another proof technique for
infinite lists, the classical take lemma \citep{introfp} by being
easier to apply and generalise: unlike the take lemma, it can be
applied to equalities of any polynomial data type
\citep{genapprox}. The definitions of \hs{approx} for lists and
\hs{take} can be seen in Figure \ref{code:takeapprox}.

%\note{write this as Haskell code? \newline (those \hs{Nat} are actually $\mathbb{N}$)}
\begin{figure}[h!]
\centering
\begin{minipage}[b]{6.2cm}
\begin{code}
take :: Nat -> [a] -> [a]
take Zero     _      = []
take (Succ n) []     = []
take (Succ n) (x:xs) = x : take n xs
\end{code}
\end{minipage}
\hspace{10pt}
\begin{minipage}[b]{6.7cm}
\begin{code}
approx :: Nat -> [a] -> [a]
approx (Succ n) []     = []
approx (Succ n) (x:xs) = x : approx n xs
\end{code}
\end{minipage}
\caption{Definition of \texttt{take} and \texttt{approx}
\label{code:takeapprox}
}
\end{figure}

Both functions in Figure \ref{code:takeapprox} can be seen as
approximating a list to a given length. The difference is the last
value in the list. \hs{take} ends the list with \hs{[]}. Since there
is no \hs{Zero} case for \hs{approx}, it ends it with $\bot$.  The
idea of these techniques is then to show that show that two lists are
equal by showing that their prefix or approximation coincides for all
natural numbers.

Now we can state the approximation lemma:

\begin{equation}
\label{eq:approxeq}
xs \, = \, ys \quad \Leftrightarrow \quad \fa{n \in \mathbb{N}} \hs{approx} \, n \, xs = \hs{approx} \, n \, ys
\end{equation}

Equation \ref{eq:approxeq} quantifies over the true natural
numbers\footnote{The true natural numbers refers here means the
  standard model of $\PA$.} (i.e. total and finite), rather than the
Haskell naturals. To prove a non-trivial equality to a proof by
induction over natural numbers. The base case for $0$ is always
trivially true by reflexivity, as the approximation of the two lists
is $\bot = \bot$. For the step case, the right to left implication is
(trivially) true by substitution, and the other direction hinges on
the lemma that better and better approximations form a chain with
limit \hs{id}, as illustrated in Equation \ref{eq:approxchain} below.

\begin{equation}
\label{eq:approxchain}
\hs{approx} \, 0 \,
   \sqsubseteq \,
\hs{approx} \, 1 \,
   \sqsubseteq \,
\cdots
   \sqsubseteq \,
\hs{approx} \, n \,
   \sqsubseteq \,
\hs{approx} \, (\hs{Succ} \, n) \,
   \sqsubseteq \,
\cdots
   \sqsubseteq \,
\hs{id}
\end{equation}

The inclusions in Equation \ref{eq:approxchain} are easily given by
induction on natural numbers and the limit by structural induction on
lists. For other polynomial data types, this lemma is established by
the structural induction induced on that data type. The desired
implication is then readily deduced:

\begin{align*}
\xsys{\fa{n} \hs{approx} \, n}{}            \\
\descra{limits}                             \\
\xsys{\lub{n} \, (\hs{approx} \, n}{)}      \\
\desclra{continuity of application}   \\
\xsys{\lub{n} \, (\hs{approx} \, n)}{}      \\
\desclra{Equation \ref{eq:approxchain}} \\
\xsys{\hs{id}}{}                            \\
\desclra{definition of \hs{id}}       \\
\xsys{}{}                                   \\
\end{align*}

This concludes the proof of the approximation lemma. The take lemma is
stated just the same but with \hs{take} instead of
\hs{approx}. However, it does not enjoy the simple chain property in
Equation \ref{eq:approxchain}, so the proof is a bit more involving.
Furthermore, generalising \hs{approx} to other sum of product
data types is simple, an example is given in the next section. For the
\hs{take} lemma it is not as simple: for some data types there is no
single nullary constructor in place for the empty list.

\subsection{Example: Mirroring an Expression}

Consider these definitions of a modest but prototypical expression
data type, and its mirroring function:

\begin{code}
data Expr = Add Expr Expr | Value Nat

mirror :: Expr -> Expr
mirror (Add e1 e2) = Add (mirror e2) (mirror e1)
mirror (Value n)   = Value n

prop_mirror_involutive :: Expr -> Prop Expr
prop_mirror_involutive e = e =:= mirror (mirror e)
\end{code}

This property that \hs{mirror} is involutive is provable by the
approximation lemma. The approximation function for \hs{Expr} can be
automatically generated by approximating each self-recursive
constructor. This relies on the fact that the type of the equality is
known, and here is the reason why the type needs to be stated in the
properties\footnote{Indeed, the types could be inferred.}. For our
data type \hs{Expr}, the generated function approximates the
sub-expressions in \hs{Add} and the \hs{Nat} in \hs{Value} is not
further approximated:

\begin{code}
approx :: Nat -> Expr -> Expr
approx (Succ n) (Add e1 e2) = Add (approx n e1) (approx n e2)
approx (Succ n) (Value n)   = Value n
\end{code}

Since \hs{Expr} does not have a nullary constructor, deriving a
\hs{take} function for it is impossible. Furthermore, fixed point
induction fails on this property: choosing either or both occurrences
of \hs{mirror} on the right side is constant bottom for the base case,
and the left side is the identity.

As always in proofs by approximation lemma, we proceed by induction
over natural numbers, and the base case is always trivial: true by
reflexivity as both sides are $\bot$. For this reason, only the step
case needs to be proved:

\begin{mathpar}
  \inferrule*
     {
         \fa{e}  \hs{approx} \, n \, e = \hs{approx} \, n \, (\hs{mirror} \, (\hs{mirror} \, e))
     }
     {
         \fa{e}  \hs{approx} \, (\hs{Succ} \, n) \, e = \hs{approx} \, (\hs{Succ} \, n) \, (\hs{mirror} \, (\hs{mirror} \, e))
     }
\end{mathpar}

An important property of the induction hypothesis is the universal
quantification of the expression $e$, unlike the fixed natural number
$n$. The proof is by cases, since for any argument, \hs{mirror} will
return a value of $\bot$, \hs{Add} or \hs{Value}.  The $bot$ case is
trivial as \hs{mirror} is strict in its first argument, and the
\hs{Value} case is also straight forward as mirroring is the identity
on this input.

\pagebreak
The \hs{Add} case is slightly more involving. The
reasoning is as follows:

\newcommand{\Adds}[2]{\hs{Add} \, #1 e_1 #2 \, #1 e_2 #2}
\newcommand{\Approxn}[0]{\hs{approx} \, n \,}
\newcommand{\ApproxSuccn}[0]{\hs{approx} \, (\hs{Succ} \, n) \,}
\newcommand{\mirmir}[0]{\hs{approx} \, n \, (\hs{mirror} \, }
\begin{align*}
lhs & = \ApproxSuccn (\Adds{}{})                                && \{\textrm{definition of \hs{approx}}\} \\
    & = \Adds{(\Approxn}{)}                                     && \{\textrm{induction hypothesis}\} \\
    & = \Adds{(\mirmir}{))}                            && \{\textrm{definition of \hs{approx}}\} \\
    & = \ApproxSuccn (\Adds{(\hs{mirror}}{)}) = rhs
\end{align*}
%
%
%\faa{e_1}{e_2}&  \ApproxSuccn (\Adds{}{})  = \ApproxSuccn (\mirmir \Adds{}{} ))                                                                   \\
%                                                                                 \desclra{\defof{$\fn{mirror}$}}                                   \\
%\faa{e_1}{e_2}&  \ApproxSuccn (\Adds{}{})  = \ApproxSuccn (\Adds{(\mirmir}{))})                                                                    \\
%                                                                                \desclra{\defof{$\fn{approx}$}}                                    \\
%\faa{e_1}{e_2}&  \Adds{(\Approxn}{)}      = \Adds{(\Approxn(\mirmir}{)))}                                                                        \\
%                                                                                \desclra{induction hypothesis twice ($e_1$ and $e_2$)} \\
%\faa{e_1}{e_2}&  \Adds{(\Approxn}{)}      = \Adds{(\Approxn}{)}                                                                                  \\
%                                                                                \desca{reflexivity}                                              \\
%\end{align*}

As the all the cases are proved, the approximation lemma proves the
property to be a theorem. The next section will investigate the
relation between approximation lemma and fixed point induction. It
will be shown that this section's technique can be expressed in terms
of fixed point induction. This makes this method lighter for theorem
provers.

\subsection{Approximation Lemma is Fixpoint Induction}

This technique is already simple and widely applicable, however it can
further be simplified. Using it with theorem provers in the form
introduced about relies on the auxiliary structure of $\PA$ natural
numbers which then needs to be added to the theory. This can be
removed by the observation that the approximation lemma can be
expressed as fixed point induction. The fixed function is a recursive
form of the identity function, which will be called \hs{ind} for its
close resemblance of induction. For lists and the \hs{Expr} data type,
\hs{ind} can be seen in Figure \ref{code:ind}.

\begin{figure}[h!]
\centering
\begin{minipage}[b]{5cm}
\begin{code}[mathescape]
ind$_{\texttt{[a]}}$ :: [a] -> [a]
ind$_{\texttt{[a]}}$ [] = []
ind$_{\texttt{[a]}}$ (x:xs) = x:ind$_{\texttt{[a]}}$ xs
\end{code}
\end{minipage}
\hspace{10pt}
\begin{minipage}[b]{8.3cm}
\begin{code}[mathescape]
ind$_{\texttt{Expr}}$ :: Expr -> Expr
ind$_{\texttt{Expr}}$ (Value n) = Value n
ind$_{\texttt{Expr}}$ (Add e1 e2) = Add (ind$_{\texttt{Expr}}$ e1) (ind$_{\texttt{Expr}}$ e2)
\end{code}
\label{code:approx}
\end{minipage}
\caption{Definition of \texttt{ind} for lists and \texttt{Expr}
\label{code:ind}
}
\end{figure}

Each \hs{ind} function constructed in this way is indeed an identity
function, equivalent to the implementation \hs{ind x = x} when
disregarding time and space complexity.
Now, to prove an equality for two expressions $e_1$ and $e_2$ with
some variables $x_1$ to $x_n$ free:

\begin{equation*}
\fa{x_1, \ldots, x_n} e_1[x_1, \ldots, x_n] \, = \, e_2[x_1, \ldots, x_n],
\end{equation*}

\noindent
one can simply use fixed point induction over $\fn{ind}$ to prove:

\begin{equation*}
\fa{x_1, \ldots, x_n} \fn{ind}(e_1[x_1, \ldots, x_n]) \, = \, \fn{ind}(e_2[x_1, \ldots, x_n])
\end{equation*}

\noindent
where $\fn{ind}$ is a such a specialised recursive identity function
over the data type of the equality. \begin{comment}With the same translation for
recursive functions as in the simplified fixed point induction section
the axioms of $\fn{ind}$ for lists are:

\begin{align*}
\rom{1} &&             & \tofix{\fn{ind}}(\fn{nil})   \eq \, \fn{nil}                                                           \\
\rom{2} && \faa{x}{xs} & \tofix{\fn{ind}}(\fn{cons}(x,xs)) \eq \fn{cons}(x,\unfix{\fn{ind}}(xs))                                                \\
\rom{3} && \fa{xs}     & \tofix{\fn{ind}}(xs)        \eq \bot \leftarrow xs \neq \fn{nil} \wedge xs \neq \fn{cons}(\fn{cons_0}(xs),\fn{cons_1}(xs)) \\
\end{align*}

\end{comment}
The step case in induction $P(\unfix{ind}) \rightarrow P(\tofix{ind})$
is then exactly the same strength as the approximation lemma with
natural numbers. With implicit universal quantification, we get this
simplified inference rule for the approximation lemma:

\begin{mathpar}
  \inferrule*
     {
                    \unfix{\fn{ind}} \w e_1 \eq \unfix{\fn{ind}} \w e_2
        \rightarrow \tofix{\fn{ind}} \w e_1 \eq \tofix{\fn{ind}} \w e_2
     }
     {
        e_1 \eq e_2
     }
\end{mathpar}

Just as fix point induction was introduced to reason about chains
without explicitly mentioning natural numbers, this technique follows
the same pattern, as it does does not rely on natural numbers.

%\subsection{Implementation} The implementation of approximation lemma
%was the simplest to implement, after definitional equality. First,
%from the type signature from the property, such a recursive identity
%function as above is generated for the data type of the equality. Then
%the lemma $P(\unfix{id})$ is added to the theory, with $P$
%instantiated to the universally quantified equality, and the
%conjecture is $P(\tofix{id})$. The base case need not be proven,
%$P(\bot)$ is always true since it evaluates to $\bot=\bot$.
%\note{Compare this to skolemization for induction? Can $\tofix{id}$ be
%  viewed as a kind of skolemization?}

\pagebreak

\subsection{Future Work: Total Approximation Lemma}
\label{sec:totalapprox}

It is also possible to adjust the approximation lemmas to prove
properties about total values. A property that is true for total list
is the idempotence of \hs{nub}. This is a version of \hs{nub} on
booleans, and with this property stated:

\begin{code}
nub :: [Bool] -> [Bool]
nub (True :True :xs) = nub (True:xs)
nub (False:False:xs) = nub (False:xs)
nub (x:xs)           = x:nub xs
nub _                = []

prop_nub_idem :: [Bool] -> Prop [Bool]
prop_nub_idem xs = nub (nub xs) =:= nub xs
\end{code}

\noindent
This is not a theorem for infinite and partial lists: Consider the
list \hs{True:False:}$\bot$. One application of \hs{nub} gives
\hs{True:}$\bot$, and two gives $\bot$ immediately. Similar results
are obtained for the infinite and total list \hs{repeat True}, however
this property is true for total finite lists and a way to adjust the
approximation lemma to prove such properties is to add a predicate
indicating totality. A value is total if it does not contain any
bottoms. This predicate can be approximated is first order equality,
and these axioms sketches out the approach for the totality theory
relevant for the \hs{nub} function:

\begin{align*}
\rom{1} &&             & \neg \, Total(\bot) \\
\rom{2} &&             & Total(\hs{[]}) \\
\rom{3} && \faa{x}{xs} & Total(x) \wedge Total(xs) \leftrightarrow Total(x\hs{:}xs) \\
\rom{4} && \fa{xs}     & Total(xs) \rightarrow Total(\hs{nub} \, xs) \\
\end{align*}

The last axiom should only be added after a proof of termination
proof. However, without an axiomatisation of set theory, it is
impossible to express totality for infinite length lists. The axioms
above are then only an approximation and will have models where
infinite total lists are $Total$ and also $\neg Total$. Hence, out
setting, $Total$ must necessarily mean finite. This is further
discussed in Section \ref{sec:total}.

Furthermore, the admissibility of this approach needs to be proved. A
simple and general case is assumed, where the predicate is defined to
be

$$P(y) \Leftrightarrow \fa{x} Q(x) \rightarrow R(x,y),$$

\noindent
and the restriction is that $R$ is admissible in the second
argument. This is the setting above with $Q$ in place of $Total$ and
$R$ the admissible equality predicate with $x$ as a free
variable. Assume a $\sqsubseteq$-chain $\langle y_n
\rangle_{n\in\omega}$ that satisfies $P$. Take some $x_0$ such that

$$\fa{n} Q(x_0) \rightarrow R(x_0,y_n)$$

If not $Q(x_0)$, then for all $y$ we have $R(x_0,y)$, and in
particular when $y=\lub{n}(y_n)$ we get $P(\lub{n}(y_n))$. If
$Q(x_0)$, then $R(x_0,\lub{n}(y_n))$ because $R$ is admissible in its
second argument. In both cases we have $P(\lub{n}(y_n))$, hence $P$
is admissible. This technique with a predicate for totality also works
for fixed point induction. Additionally, the predicate $Q$ can also be a
predicate indicating type.
