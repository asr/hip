\section{Approximation Lemma}
\label{sec:approx}

The approximation lemma is another standard technique for proving
properties about corecursive programs. Just like fixed point induction
it can be used with functions that are produce infinite values, like
\hs{repeat} and \hs{iterate}, out of abstract values making structural
induction impossible \cite{corecursive}, but the approximation lemma
usually supersedes lemma fixed point induction since it is much
simpler to apply.

The approximataion lemma supersedes the classical take lemma
\cite{introfp} by being easier to apply and generalize: unlike the
take lemma, it can be applied to equalities of any polynomial data
type \cite{genapprox}. The definitions of \hs{take} and \hs{approx}
can be seen in Figure \ref{code:takeapprox}.

%\note{write this as Haskell code? \newline (those \hs{Nat} are actually $\mathbb{N}$)}
\begin{figure}[h!]
\centering
\begin{minipage}[b]{6.2cm}
\begin{code}
take :: Nat -> [a] -> [a]
take Zero    _      = []
take (Suc n) []     = []
take (Suc n) (x:xs) = x : take n xs
\end{code}
\end{minipage}
\hspace{10pt}
\begin{minipage}[b]{6.7cm}
\begin{code}
approx :: Nat -> [a] -> [a]
approx (Suc n) []     = []
approx (Suc n) (x:xs) = x : approx n xs
\end{code}
\end{minipage}
\caption{Definition of \texttt{take} and \texttt{approx}
\label{code:takeapprox}
}
\end{figure}

Whereas \hs{take} approximates a list and ends it with \hs{[]},
\hs{approx} ends it with $\bot$ since the \hs{Zero} case is
omitted. The idea of these techniques is then to show that show that
two lists are equal by showing that their prefix or approximation
coincides for all natural numbers.

\newpage
Now we can state the approximation lemma:

\begin{equation}
\label{eq:approxeq}
xs \, = \, ys \quad \Leftrightarrow \quad \fa{n \in \mathbb{N}} \hs{approx} \, n \, xs = \hs{approx} \, n \, ys
\end{equation}

Equation \ref{eq:approxeq} quantifies over the real natural numbers
(i.e. total and finite), rather than the Haskell naturals. Showing an
equality then amounts to a proof by induction over natural numbers,
and the base case for $0$ is always true by reflexivity, as the
approximation of the two lists is $\bot = \bot$. The right to left
implication is (trivially) true by substitution, and the other
direction hinges on the lemma that better and better approximations
form a chain with limit \hs{id}, as illustrated in Equation
\ref{eq:approxchain} below.

\begin{equation}
\label{eq:approxchain}
\hs{approx} \, 0 \,
   \sqsubseteq \,
\hs{approx} \, 1 \,
   \sqsubseteq \,
\cdots
   \sqsubseteq \,
\hs{approx} \, n \,
   \sqsubseteq \,
\hs{approx} \, (\hs{Suc} \, n) \,
   \sqsubseteq \,
\cdots
   \sqsubseteq \,
\hs{id}
\end{equation}

The inclusions in Equation \ref{eq:approxchain} are easily given by
induction on natural numbers and the limit by structural induction on
lists.  For other polynomial data types, this lemma is established by
the structural induction induced on that data type.  The desired
implication is then readily deduced:

\begin{align*}
\xsys{\fa{n} \hs{approx} \, n}{}            \\
\descra{limits}                             \\
\xsys{\lub{n} \, (\hs{approx} \, n}{)}      \\
\desclra{continuity of application}   \\
\xsys{\lub{n} \, (\hs{approx} \, n)}{}      \\
\desclra{Equation \ref{eq:approxchain}} \\
\xsys{\hs{id}}{}                            \\
\desclra{definition of \hs{id}}       \\
\xsys{}{}                                   \\
\end{align*}

\subsection{Example: Mirroring an Expression}

Consider these definitions of a modest but prototypical expression
data type, and its mirroring function:

\begin{code}
data Expr = Add Expr Expr | Value Nat

mirror :: Expr -> Expr
mirror (Add e1 e2) = Add (mirror e2) (mirror e1)
mirror (Value n)   = Value n

prop_mirror_involutive :: Expr -> Prop Expr
prop_mirror_involutive e = e =:= mirror (mirror e)
\end{code}

The type \hs{Expr} does not have a nullary constructor. Then the
\hs{take} lemma would not be usable as there is no such function over
these expressions: the list version returns the empty list \hs{[]} for
the zero case, but there is no such alternative for \hs{Expr}
above. It is important that the limit of approximations is the
identity, and we cannot get this property when trying to generalise
the take lemma.

Furthermore, fixed point induction fails on this property: choosing
either or both occurrences of \hs{mirror} on the right side is
constant bottom for the base case, and the left side is the identity.

We shall now proceed to prove that \hs{mirror} is involutive by the
approximation lemma. The approximation function for \hs{Expr} is
automatically generated, by approximating each self-recursive
constructor, and hence \hs{Value}'s \hs{Nat} is not further approximated:

\begin{code}
approx :: Nat -> Expr -> Expr
approx (Suc n) (Add e1 e2) = Add (approx n e1) (approx n e2)
approx (Suc n) (Value n)   = Value n
\end{code}

\note{Use $\bot$ or bottom in this text?}
Indeed, we also get a third case for $\bot$ which states that the
approximation of $\bot$ is, quite unsurprisingly, $\bot$.
As always in proofs by approximation lemma, we proceed by induction
over natural numbers, and the base case is always trivial: true by
reflexivity as both sides are $\bot$. The step case - which indeed is
the only proof obligation in any proof of this kind - is to prove

this:

\begin{equation*}
\fa{e}  \hs{approx} \, (\hs{Suc} \, n) \, e = \hs{approx} \, (\hs{Suc} \, n) \, (\hs{mirror} \, (\hs{mirror} \, e))
\end{equation*}

An important property of the induction hypothesis is the universal
quantification of the expression $e$, unlike the fixed natural number
$n$:

\begin{equation*}
\fa{e}  \hs{approx} \, n \, e = \hs{approx} \, n \, (\hs{mirror} \, (\hs{mirror} \, e))
\end{equation*}

The proof is by case exhaustion. The case for \hs{Value} and $\bot$
are trivial: \hs{mirror} is strict in its first argument, and
mirroring \hs{Value} twice is the identity, so these cases are both
true by reflexivity. The \hs{Add} case is ever so slightly more
elaborate, and with names shortened to $\hs{app}$ and $\hs{mir}$ the
reasoning is as follows:

\note{$(\hs{Suc} \, n)$ or $(n + 1)$?}
\newcommand{\Adds}[2]{\hs{add} \, #1 e_1 #2 \, #1 e_2 #2}
\newcommand{\Approxn}[0]{\hs{app} \, n \,}
\newcommand{\ApproxSucn}[0]{\hs{app} \, (\hs{Suc} \, n) \,}
\newcommand{\mirmir}[0]{\hs{mir} \, (\hs{mir} \, }
\begin{align*}
\faa{e_1}{e_2}&  \ApproxSucn (\Adds{}{})  = \ApproxSucn (\mirmir \Adds{}{} ))                                                                   \\
                                                                                 \desclra{\defof{\texttt{mirror}}}                                   \\
\faa{e_1}{e_2}&  \ApproxSucn (\Adds{}{})  = \ApproxSucn (\Adds{(\mirmir}{))})                                                                    \\
                                                                                \desclra{\defof{\texttt{approx}}}                                    \\
\faa{e_1}{e_2}&  \Adds{(\Approxn}{)}      = \Adds{(\Approxn(\mirmir}{)))}                                                                        \\
                                                                                \desclra{induction hypothesis twice ($e_1$ and $e_2$)} \\
\faa{e_1}{e_2}&  \Adds{(\Approxn}{)}      = \Adds{(\Approxn}{)}                                                                                  \\
                                                                                \desca{reflexivity}                                              \\
\end{align*}

\subsection{Approximation Lemma is Fixpoint Induction}

This technique is already simple and widely applicable, however it can
further be simplified. Implementing it in this form relies on the
auxiliary structure of Peano natural numbers which also needs to be
added to the theory. This can be removed by the observation that is
expressed as fixed point induction over a recursive form of the
identity function, called \hs{ind} for its close resemblance of
induction. For lists and the \hs{Expr} data type, \hs{ind} can be seen
in Figure \ref{code:ind}.

\begin{figure}[h!]
\centering
\begin{minipage}[b]{5cm}
\begin{code}[mathescape]
ind$_{\texttt{[a]}}$ :: [a] -> [a]
ind$_{\texttt{[a]}}$ [] = []
ind$_{\texttt{[a]}}$ (x:xs) = x:ind$_{\texttt{[a]}}$ xs
\end{code}
\end{minipage}
\hspace{10pt}
\begin{minipage}[b]{8.3cm}
\begin{code}[mathescape]
ind$_{\texttt{Expr}}$ :: Expr -> Expr
ind$_{\texttt{Expr}}$ (Value n) = Value n
ind$_{\texttt{Expr}}$ (Add e1 e2) = Add (ind$_{\texttt{Expr}}$ e1) (ind$_{\texttt{Expr}}$ e2)
\end{code}
\label{code:approx}
\end{minipage}
\caption{Definition of \texttt{ind} for lists and \texttt{Expr}
\label{code:ind}
}
\end{figure}

Each \hs{ind} function constructed in this way is indeed an identity
function, equivalent to the implementation \hs{id x = x} if we
disregard time and space complexity. Now, to prove

\begin{equation*}
e_1 \, = \, e_2
\end{equation*}

we simply use fixed point induction to prove

\begin{equation*}
\hs{ind} \, e_1 \, = \, \hs{ind} \, e_2
\end{equation*}

where \hs{ind} is a such a specialized recursive identity function
over the data type of the equality. With the same translation for
recursive functions as in the fixed point section the axioms of
\hs{ind} for lists are:

\begin{align*}
\rom{1} &&             & \tofix{\fn{ind}}(\fn{nil})   \eq \, \fn{nil}                                                           \\
\rom{2} && \faa{x}{xs} & \tofix{\fn{ind}}(\fn{cons}(x,xs)) \eq \fn{cons}(x,\unfix{\fn{ind}}(xs))                                                \\
\rom{3} && \fa{xs}     & \tofix{\fn{ind}}(xs)        \eq \bot \leftarrow xs \neq \fn{nil} \wedge xs \neq \fn{cons}(\fn{cons_0}(xs),\fn{cons_1}(xs)) \\
\end{align*}

The step case in induction $P(\unfix{id}) \rightarrow P(\tofix{id})$
is then exactly the same strength as the approximation lemma with
natural numbers. We get this simple rule for approximation lemma:

\begin{mathpar}
  \inferrule*
     {
                    \unfix{\fn{ind}} \w e_1 \eq \unfix{\fn{ind}} \w e_2
        \rightarrow \tofix{\fn{ind}} \w e_1 \eq \tofix{\fn{ind}} \w e_2
     }
     {
        e_1 \eq e_2
     }
\end{mathpar}

Just as fix point induction was introduced to reason about chains
without explicitly relying on natural numbers, this follows the same
pattern. This version of the approximation lemma does not rely on natural
numbers.


%\subsection{Implementation} The implementation of approximation lemma
%was the simplest to implement, after definitional equality. First,
%from the type signature from the property, such a recursive identity
%function as above is generated for the data type of the equality. Then
%the lemma $P(\unfix{id})$ is added to the theory, with $P$
%instantiated to the universally quantified equality, and the
%conjecture is $P(\tofix{id})$. The base case need not be proven,
%$P(\bot)$ is always true since it evaluates to $\bot=\bot$.
%\note{Compare this to skolemization for induction? Can $\tofix{id}$ be
%  viewed as a kind of skolemization?}

\subsection{Future Work: Total Approximation Lemma}

It would be nice to adjust the approximation lemma to prove properties
that are true for total and potentially infinite objects, but false
for objects with partial values. One such property is the idempotence
of \hs{nub}. Here is a version of \hs{nub} on booleans, and the said
property about it:

\begin{code}
nub :: [Bool] -> [Bool]
nub (True :True :xs) = nub (True:xs)
nub (False:False:xs) = nub (False:xs)
nub (x:xs)           = x:nub xs
nub _                = []

prop_nub_idem :: [Bool] -> Prop [Bool]
prop_nub_idem xs = nub (nub xs) =:= nub xs
\end{code}

Consider the list \hs{True:False:}$\bot$. One application of \hs{nub}
gives \hs{True:}$\bot$, and two gives $\bot$ immediately. In spite of
this, the property is a truism for finite as well as infinite lists,
provided that there are not bottoms.

The way to enable the approximation lemma to prove such properties is
to add predicates of totality, and add axioms like the following to
the theory:

\begin{align*}
\rom{1} &&             & \neg \, Total(\bot) \\
\rom{2} &&             & Total(\hs{[]}) \\
\rom{3} && \faa{x}{xs} & Total(x) \wedge Total(xs) \rightarrow Total(x\hs{:}xs) \\
\rom{4} && \fa{xs}     & Total(xs) \rightarrow Total(\hs{nub} \, xs) \\
\end{align*}

Though \hs{Total} is an admissible predicate, we want to use it as an
implication, to use fixed point induction on \hs{ind} to prove
something like this:

\begin{equation*}
\fa{xs} Total(xs)\rightarrow \hs{ind} \w (\hs{f} \w xs) = \hs{ind} \w (\hs{g} \w xs)
\end{equation*}

\noindent
However, this is not admissible. We are searching for another
formulation that is.

