\section{Fixed Point Induction}
\label{sec:fixpoint}

Structural induction is applicable when at least one argument is of a
concrete type, such as lists or trees. There are also properties where
all arguments are of abstract types. A canonical example is the
map-iterate property::

\begin{equation*}
\faa{f}{x} \hs{map} \w f \w (\hs{iterate} \w f \w x) \eq
           \hs{iterate} \w f \w (f \w x)
\end{equation*}

Here $f$ is any function of type $a \rightarrow a$, and $x$ is a value
of type $a$. This example is further investigated in Section
\ref{sec:mapiter} below, but it is already clear that this property
cannot be proved with structural induction since there is no argument
of a concrete type.

Enter fixed point induction. It gives a way of performing induction on
the recursive structure of the program. In short, if the property
regards a function $f$, the hypothesis is that the property holds for
all the recursive calls in the definition of $f$, and the goal is to
prove that it holds for $f$. The origin of the name is the use of the
fixed point combinator, which is traditionally defined in Haskell as
\hs{fix}:

\begin{code}
fix :: (a -> a) -> a
fix f = f (fix f)
\end{code}

Fixed point induction can prove properties about \hs{fix f} for some
\hs{f}, and the next section gives a method to rewrite any recursive
functions in terms of \hs{fix}. Then properties about recursive
functions in general can be proved by fixed point induction.

The fixed point in question is the solution of the fixed point
equation $x = f \w x$. The function \hs{fix} solves this equation:
substitute $x$ for $\hs{fix} \w x$, then the left side evaluates to $f
\w (\hs{fix} \w f)$ in one step, which is then equal to the right
side. This is the origin of the name of the combinator \hs{fix}: this
is a fixed point of the equation, furthermore it is the least fixed
point \citep{domains}.

\begin{comment}
The domain theoretic approach is to say that
$\hs{fix} \w f \eq \lub{n}(f^n \bot)$, where $f^n \bot$ is $n$
applications of $f$:
\begin{equation*}
f^n \bot \eq \underbrace{f (f (\cdots (f}_{n \w \mathrm{copies \w of} \w f}} \bot) \cdots))
\end{equation*}
This corresponds to a potentially infinite, countable unrolling of $f$.
It is easy to verify that $\langle f^n \bot\rangle_{n\in\omega}$ is a
$\sqsubseteq$-chain by induction on $n$, and that this is the least
pre-fixed point of $f$ is also showed by induction: Assume there
is another pre-fixed point $\theta$, thus satisfying
$\theta \eq f \w \theta$. The base case is
$\bot \eq f^0 \bot \sqsubseteq \theta$, trivially satisfied since
$\bot$ is the least element. For the step case, assume that
$f^n \bot \sqsubseteq \theta$, and we get the conclusion
$f^{n+1} \bot = f (f^n \bot) \sqsubseteq f \w \theta = \theta$ as desired.
\end{comment}

\subsection{Rewriting Functions in Terms of \texttt{fix}}

Any self-recursive function can be rewritten in terms of
\hs{fix} \citep{YMcAdam}. This is a mechanical translation which simply prepends a new
argument which is used for each recursive call of the function. This
is exemplified for the \hs{map} function in Figure \ref{code:mapfix}
below. A new argument \hs{m} is introduced and the recursive call uses
\hs{m} instead of \hs{map}.

\begin{figure}[h!]
\centering
\begin{minipage}[b]{6cm}
\begin{code}[mathescape]
map :: (a -> b) -> [a] -> [b]
map f (x:xs) = f x : map f xs
map f [] = []
$\newline$
$\newline$
\end{code}
\end{minipage}
\hspace{10pt}
\begin{minipage}[b]{6cm}
\begin{code}
map' m f (x:xs) = f x : m f xs
map' m f [] = []

map :: (a -> b) -> [a] -> [b]
map = fix map'
\end{code}
\end{minipage}
\caption{The standard definition of \texttt{map} and a definition in
  terms of \texttt{fix}
\label{code:mapfix}
}
\end{figure}

The correctness of the translation of \hs{map} in Figure
\ref{code:mapfix} is immediate: \hs{fix map'} evaluates to \hs{map'
  (fix map')} by the definition of \hs{fix}, which means that the
recursive function \hs{m} is \hs{fix map'}. By construction it is then
equal to the original definition of \hs{map}.

Generally, for a function \hs{f} with $n \geq 0$ arguments $\hs{x}_1$
to $\hs{x}_n$ and a body $e[\hs{f},\hs{x}_1,\ldots,\hs{x}_n]$ with
these variables free, the definition in terms of \hs{fix} is:

\begin{align*}
& \hs{f } \hs{x}_1 \ldots \hs{x}_n \hs{ = } e[\hs{f},\hs{x}_1,\ldots,\hs{x}_n] & \Rightarrow &&& \fixhsb{f} \w \fixhsw{f} \w \hs{x}_1 \ldots \hs{x}_n \hs{ = } e[\fixhsw{f},\hs{x}_1,\ldots,\hs{x}_n] \\
&                                                                     &             &&& \hs{f = fix} \w \fixhsb{f}
\end{align*}

The funny notation with filled and outlined circles carry some
meaning. The black dot in $\fixhsb{f}$ indicates that this function
has an implementation, mnemonic filled with implementation. The
outlined circle in $\fixhsw{f}$ means that this function does not have
any implementation, it is empty. However, when $\hs{fix }\fixhsb{f}$
unrolls this will replace $\fixhsw{f}$.

\begin{comment}
This translation needs to be carried out with some care, since for $f
\, \overline{x} = e(\overline{x},f)$, it is also possible that $f$ is
called in bodies of other functions. These are of two kinds: either
this function is also called from $f$, making it recursive, or another
function which is not called from $f$, but makes use of $f$
anyway. The first example, with a recursive call, the body needs to be
edited so $f$ becomes translated (to $\bot$, $\unfix{f}$ or
$\tofix{f}$), and the second case should use the original $f$. The
transitive closure of the call graph is calculated, and every
appropriate calls of $f$ are replaced.
\end{comment}

%\noindent
As promised, fix point induction proves properties about a function written in terms
of \hs{fix}, and its inference rule will be stated in the next section.

\subsection{Inference Rule}

Fixed point induction can show a property $P$ about \hs{fix f} for
some function \hs{f}. The base case is to show that $P$ holds when the
function is replaced with $\bot$, which corresponds to zero
``unrolls'' of the function. For the step case, assume $P$
holds for a function $x$, and the goal is to show $P(\hs{f} \w x)$.
Intuitively, we can see $x$ as a number of ``enrolling'' of the
function and we need to show for the next. Moreover, it can also be
seen as $x$ corresponds to all the recursive occurrences in the body of
the function, and we need to show it for the real function.

Using the notation from \cite{corecursive}, we now state its
inference rule:


\begin{mathpar}
  \inferrule*
     {
       P(\bot)
       \\
       P(x) \rightarrow P(f \w x)
       \\
       P \w \mathrm{admissible}
     }
     { P(\fn{fix} f) }
\end{mathpar}

Admissible predicates was introduced in Section \ref{sec:admissible},
and just as structural induction with the bottom base case, this
induction technique also has the admissibility requirement on the
predicate. Again, predicates from equality properties are admissible.

An interesting property of fixed point induction is that it does not
care about types. Indeed, it works in an untyped setting. In addition,
it can exploit arbitrary recursive structures of the function. A
caveat is that it can only prove properties that must hold for
infinite and partial values.

Fixed point induction is a consequence of induction of natural
numbers. The proof for this relies on the fact that $\lub{n}(f^n \w
\bot) \eq \hs{fix} \, f$, where $f^n$ is $n$ self-applications of
$f$. This is true since \hs{fix} is defined as $f$ applied to it
self. The proof also uses induction over natural numbers and that $f^0
\w \bot \eq \bot$, and the admissibility of $P$. Proof:

\begin{align*}
P(\bot) & \wedge \fa{x} P(x) \rightarrow P(f x) \\
\desclra{$f^0 \w \bot \eq \bot$} \\
P(f^0 \w \bot) & \wedge \fa{x} P(x) \rightarrow P(f x) \\
\descra{instantiation of $x$ to $f^n$} \\
P(f^0 \w \bot) & \wedge \fa{n} P(f^n \w \bot) \rightarrow P(f^{n+1} \w \bot) \\
\descra{induction over $\mathbb{N}$} \\
\fa{n} & P(f^n \w \bot) \\
\descra{\textit{P} admissible} \\
& P(\lub{n}(f^n \w \bot)) \\
\descra{definition of \hs{fix}} \\
& P(\hs{fix} \w f) \\
\end{align*}

\noindent
One reason to introduce fixed point induction is to avoid the natural
numbers in $\fa{n} P(f^n \bot)$ to prove $P(\hs{fix} \w f)$.

The necessary theory ought to be explained by now, so the next section
shows how to apply fixed point induction on the example in the
introduction.

\subsection{Example: map-iterate}
\label{sec:mapiter}

For properties that do not have any arguments with a concrete type,
structural induction is not applicable. The Haskell function
\hs{iterate} is a that makes an infinite list from a seed, by repeated
application of a function, i.e \hs{iterate f x} is the list
 \hs{x:f x:f (f x):}$\cdots$. It is related to Haskell function
 \hs{map} in the map-iterate property, stated as follows:

\begin{equation*}
\faa{f}{x} \hs{map} \w f \w (\hs{iterate} \w f \w x) \eq
           \hs{iterate} \w f \w (f \w x)
\end{equation*}

\noindent
The standard definition of \hs{map} was given above and \hs{iterate}
is defined as this:

\begin{code}
iterate :: (a -> a) -> a -> [a]
iterate f x = x : iterate f (f x)
\end{code}

The behaviour of \hs{map} is to apply a function to every element of a
list. We see that we cannot use structural induction here, since both
$f$ and $x$ are abstract, but the \hs{map}-\hs{iterate} property can
be proved by fixpoint induction on \hs{iterate}. First, we rewrite
this function in terms of \hs{fix}:

\begin{code}
iterate = fix iter
iter i f x = x : i f (f x)
\end{code}

\noindent
The predicate $P$ is defined to be $P(i) \w \Leftrightarrow \w
\faa{f}{x} \hs{map} \w f \w (i \w f \w x) \eq i \w f \w (f \w x)$.
If the base and the step case is shown $P(\hs{fix iter})$ can be
concluded, which by definition is $P(\hs{iterate})$.

The base case is $P(\bot)$. Since \hs{map} is strict in its second
argument, it is both the left side and right side evaluate to $\bot$.
The for the step case we have to show $P(\hs{i}) \rightarrow
P(\hs{iter i})$.  The proof without explicitly writing out function
pointer applications looks like this:

\begin{align*}
lhs & = \hs{map} \w f \w (\hs{iter} \w \hs{i} \w f \w x)          && \{\textrm{definition of \hs{iter}}\} \\
    & = \hs{map} \w f \w (x \hs{:} \hs{i} \w f \w (f \w x))       && \{\textrm{definition of \hs{map}} \} \\
    & = f \w x \hs{:} \hs{map} \w f \w (\hs{i} \w f \w (f \w x))) && \{\textrm{induction hypothesis} \} \\
    & = f \w x \hs{:} \hs{i} \w f \w (f \w (f \w x)))             && \{\textrm{definition of \hs{iter}} \} \\
    & = \hs{iter} \w \hs{i} \w f \w (f \w x) = rhs
\end{align*}
%\w \faa{f}{x}  & \eq \hs{i} \w f \w (f \w x) \\
%\descra{generalising $x$ to $f \w x$} \\
%\w \faa{f}{x} \hs{map} \w f \w (\hs{i} \w f \w (f \w x)) & \eq \hs{i} \w f \w (f \w (f \w x)) \\
%\descra{substitution} \\
%\w \faa{f}{x} f \w x \hs{:} \hs{map} \w f \w (\hs{i} \w f \w (f \w x)) & \eq f \w x \hs{:} \hs{i} \w f \w (f \w (f \w x)) \\
%\desclra{\defof{\texttt{map}}} \\
%\w \faa{f}{x} \hs{map} \w f \w (x \hs{:} \hs{i} \w f \w (f \w x)) & \eq f \w x \hs{:} \hs{i} \w f \w (f \w (f \w x)) \\
%\desclra{\defof{\texttt{iter}}} \\
%\w \faa{f}{x} \hs{map} \w f \w (\hs{iter} \w \hs{i} \w f \w x) & \eq \hs{iter} \w \hs{i} \w f \w (f \w x) \\
%\end{align*}

Now fixed point induction gives the \hs{map}-\hs{iterate} property.



\begin{comment}
\subsection{Mutually Recursive Functions}

You can also mechanically transform mutually recursive functions to be
defined in terms of \hs{fix}. The functions \hs{even} and \hs{odd}
defined below, which determines if a \hs{Nat} is even, and odd,
respectively, are straightforwardly written by mutual recursion:

\begin{code}
even :: Nat -> Bool           odd :: Nat -> Bool
even Z     = True             odd Z     = False
even (S x) = odd x            odd (S x) = even x
\end{code}

To write these functions in terms of fix, as an additional argument,
the take a tuple of ``non-recursive'' copies of themselves.

\begin{code}
evenToFix :: (Nat -> Bool,Nat -> Bool) -> Nat -> Bool
evenToFix (evenUnFix,oddUnFix) Z     = True
evenToFix (evenUnFix,oddUnFix) (S x) = oddUnFix x

oddToFix :: (Nat -> Bool,Nat -> Bool) -> Nat -> Bool
oddToFix (evenUnFix,oddUnFix) Z     = True
oddToFix (evenUnFix,oddUnFix) (S x) = evenUnFix x
\end{code}

Here the prefix \hs{ToFix} means that it is a function subject to be
\hs{fix}-ed, and \hs{UnFix} means that it is the ``non-recursive''
function. The functions above can now be \hs{fix}-ed by giving the
tuple as an argument to both of them:

\begin{code}
even',odd' :: Nat -> Bool
(even',odd') = fix (\t -> (evenToFix t,oddToFix t))
\end{code}

This encoding makes \hs{even'} denotationally equal to \hs{even} and
the same relation hols for \hs{odd'} and \hs{odd}.
\end{comment}

\subsection{Simplification}

The mechanical translation introduced above for self-recursive
functions introduces a new function with an additional argument, the
``non-recursive'' version of itself. The generated first order
function would use the new argument as a function pointer, which in
turn means a lot of use of the $\appfn$. This can be seen in the cons
case for \hs{map}:

\begin{align*}
  \faaa{m}{x}{xs} \fn{map'}(m,x\fn{:}xs) = (\app{f}{x}) \fn{:} (\app{(\app{m}{f})}{xs})
\end{align*}

This gives unnecessary overhead to the automated theorem provers.
There is another approach. It avoids introducing these function
pointers and the additional argument to every function. Consider the
translation of a function \hs{f} with the same setting as before: $n
\geq 0$ arguments $\hs{x}_1$ to $\hs{x}_n$ and a body
$e[\hs{f},\hs{x}_1,\ldots,\hs{x}_n]$ with these variables free,
instead this translation is made:

\begin{align*}
& \hs{f } \hs{x}_1 \ldots \hs{x}_n \hs{ = } e[\hs{f},\hs{x}_1,\ldots,\hs{x}_n] & \Rightarrow &&& \fixhsb{f} \w \hs{x}_1 \ldots \hs{x}_n \hs{ = } e[\fixhsw{f},\hs{x}_1,\ldots,\hs{x}_n] \\
\end{align*}

Two new functions are introduced to the vocabulary: $\fixhsb{f}$ and
$\fixhsw{f}$. The empty circle $\unfix{}$ describes that this function
is empty (lacks implementation,) and the filled circle $\tofix{}$
means that this function has an implementation. This implementation is
in terms of the unfilled version. The fixed point induction schema can
now be stated using these functions:

\begin{mathpar}
  \inferrule*
     {
       P(\bot)
       \\
       P(\unfix{f}) \rightarrow P(\tofix{f})
       \\
       P \, \mathrm{admissible}
     }
     { P(f) }
\end{mathpar}

\noindent
The empty circle in $\unfix{f}$ indicates that it does not have any
implementation, but the induction hypothesis is asserted for it. The
induction conclusion is to prove the property for $\tofix{f}$, where
the recursive call to $f$ is replaced with $\unfix{f}$. This
simplification is done since it is better suited for the theorem
provers.

Further, it is now necessary to ``inline'' the predicate in the
generated theory. The reason is that $\fixb{f}$ and $\fixw{f}$ are
first order functions rather than expressible as pointers, and
predicates that quantify over functions are not first order
expressible. Such ``inlining'' is also beneficial for theorem provers
as unnecessary predicates are not introduced to the theory.

\paragraph{Mutually recursive functions} It is also possible to
rewrite a group of mutually recursive functions by packing the
``non-recursive'' copies of themselves in a tuple. The inference rule
for two functions at the same time, possibly mutually recursive then
looks like this:

\begin{mathpar}
  \inferrule*
     {
       P(\bot,\bot)
       \\
       P(\unfix{f},\unfix{g}) \rightarrow P(\tofix{f},\tofix{g})
       \\
       P \, \mathrm{admissible}
     }
     { P(f,g) }
\end{mathpar}

\noindent
This also works when the functions are not mutually recursive. An
example is the map-iterate property which can be proved by fixating
both \hs{map} and \hs{iterate}.

\subsection{Erroneous Use of Fixed Point Induction}

It is crucial that $P$ is admissible to avoid deriving falsities. This
section gives a simple example of what can happen otherwise. Recall
the definition of the infinite natural number:

\begin{code}
inf = Succ inf
\end{code}

\noindent
A predicate that is not admissible will deliberately be used to
``prove'' that $\hs{inf} \neq \hs{Succ inf}$.  The predicate is $P(x)
\Leftrightarrow x \neq \fn{succ}(x)$. Furthermore, \hs{inf} is
translated to first order logic and rewritten in terms of $\unfix{}$ and
$\tofix{}$, as introduced in the previous section:

\begin{equation*}
\tofix{\fn{inf}} = \fn{succ}(\unfix{\fn{inf}})
\end{equation*}

\noindent
Now we proceed by ``fixed point induction''. Base case: $\bot \neq
\fn{succ}(\bot)$ is true by the axioms of disjoint constructors. Step
case: assume $\unfix{\fn{inf}} \neq \fn{succ}(\unfix{\fn{inf}})$.
Injectivity of $\fn{succ}$ gives $\fn{succ}(\unfix{\fn{inf}}) \neq
\fn{succ}(\fn{succ}(\unfix{\fn{inf}}))$.  By the definition of
$\tofix{\fn{inf}}$, which is then equal to the goal $\tofix{\fn{inf}} \neq
\fn{succ}(\tofix{\fn{inf}})$.

The conclusion $\hs{inf} \neq \hs{Succ inf}$ is clearly nonsense as it
directly contradicts the definition of $\hs{inf}$! A consequence of
this example is that inequality is in general not admissible.

%\end{comment}

\subsection{Candidate Selection}

Faced with the following property saying that if you drop $n$ elements
from a list the length of this is the same as the length of the
original list minus $n$, which functions should one do fixed point
induction on?

\begin{code}
prop_length_drop :: [a] -> Nat -> Prop Nat
prop_length_drop xs n = length (drop n xs) =:= length xs - n
\end{code}

\noindent
The answer is to do fixed point induction on \hs{drop}, and on
\hs{-}. So far no better way to tackle this is used than to try fixed
point induction on all subsets of recursive functions mentioned in the
property.

\subsection{Future Work}

Just as with structural induction, it is also possible to use fixed
point in more than one ``depth'', giving for instance this inference
rule:

\begin{mathpar}
  \inferrule*
     {
       P(\bot)
       \\
       P(f \w \bot)
       \\
       P(x) \wedge P(f \w x) \rightarrow P(f \w (f \w x))
       \\
       P \w \mathrm{admissible}
     }
     { P(\fn{fix} f) }
\end{mathpar}

It is also possible to use such an encoding as in ``Automated depth''
in Section \ref{sec:futind} to let the theorem prover determine the
depth. As an example, the map-iterate property impossible to show with
\hs{map} redefined to \hs{doublemap}, defined below, with ordinary one
depth fixed point induction.

\begin{code}
doublemap :: (a -> b) -> [a] -> [b]
doublemap f []       = []
doublemap f [x]      = [f x]
doublemap f (x:y:zs) = f x : f y : doublemap f zs
\end{code}

\noindent
Although \hs{doublemap} is behaviourally equivalent to \hs{map} on total
lists, it makes the induction hypothesis in fixed point induction too
weak.


An issue with the candidate selection is that is some selections are
immediate dead ends. An example is fixating functions on only one side
of the equality, then the base case will generally never succeed
unless the other side is constant bottom. A heuristic to find good
candidates would be beneficial.
